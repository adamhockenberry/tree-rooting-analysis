{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import ete3\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MP_root_ete3(tree):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    init_bl = np.sum([i.dist for i in tree.traverse()])\n",
    "    init_terms = tree.get_leaves()\n",
    "    init_term_names = [i.name for i in tree.get_leaves()]\n",
    "    if len(tree.children) == 3:\n",
    "        tree.set_outgroup(tree.get_leaves()[0])\n",
    "    assert set([len(i.children) for i in tree.traverse() if not i.is_leaf()]) == set([2])\n",
    "    ###Identifying the two leaves that are farthest from one-another\n",
    "    starting, trash = tree.get_farthest_leaf()\n",
    "    farthest1, init_dist = starting.get_farthest_node()\n",
    "    farthest2, max_dist = farthest1.get_farthest_node()\n",
    "    assert farthest1.is_leaf() and farthest2.is_leaf()\n",
    "    \n",
    "    ###Actually performing the mid-point root\n",
    "    final_root(tree, farthest1, farthest2, max_dist)\n",
    "    \n",
    "    ###Making sure the two leave are equi-distant from one-another\n",
    "    assert np.isclose(tree.get_distance(farthest1), tree.get_distance(farthest2))\n",
    "    ###Making sure that I didn't lose any branch length along the way\n",
    "    final_bl = np.sum([i.dist for i in tree.traverse()])\n",
    "    assert np.isclose(init_bl, final_bl)\n",
    "    ###Making sure I didn't lose any leaves along the way\n",
    "    assert set(init_term_names) == set([i.name for i in tree.get_leaves()])\n",
    "    ###And that I'm still fully bifurcating\n",
    "    assert set([len(i.children) for i in tree.traverse() if not i.is_leaf()]) == set([2])\n",
    "    return\n",
    "\n",
    "def get_ancestor_path(parent, target):\n",
    "    temp_node = target\n",
    "    path = []\n",
    "    while temp_node != parent:\n",
    "        path.append(temp_node)\n",
    "        temp_node = temp_node.up\n",
    "    return path\n",
    "\n",
    "def get_shortest_path(tree, node1, node2):\n",
    "    lca = tree.get_common_ancestor(node1, node2)\n",
    "    path1 = get_ancestor_path(lca, node1)\n",
    "    path2 = get_ancestor_path(lca, node2)\n",
    "    path2 = path2[::-1] ###Reverse this list to correctly orient the final path\n",
    "    path = path1+path2\n",
    "    return path\n",
    "\n",
    "def final_root(tree, farthest1, farthest2, max_dist):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    path = get_shortest_path(tree, farthest1, farthest2)\n",
    "    assert np.isclose(np.sum([i.dist for i in path]), max_dist)\n",
    "    ###Finding the correct branch for the final root\n",
    "    mid_point = max_dist/2.\n",
    "    counter = 0\n",
    "    for node in path:\n",
    "        counter += node.dist\n",
    "        if counter < mid_point:\n",
    "            last_success = node\n",
    "        else:\n",
    "            remainder = counter - mid_point\n",
    "            break        \n",
    "    ###Rooting the tree accordingly\n",
    "    tree.set_outgroup(node)\n",
    "    ###Checking the orientation (asking whether the other node is indeed a child)\n",
    "    if tree.children[0] != node:\n",
    "        tree.swap_children()\n",
    "    ###If the topology doesn't get deformed by the rooting\n",
    "    if tree.children == [node, last_success]:\n",
    "        total = np.sum([i.dist for i in tree.children])\n",
    "        tree.children[0].dist = remainder\n",
    "        tree.children[1].dist = total-remainder\n",
    "    ###And if it does induce a topology deformation\n",
    "    else:\n",
    "        assert last_success in tree.children[1].children        \n",
    "        total = np.sum([i.dist for i in tree.children + [last_success]])\n",
    "        tree.children[0].dist = remainder\n",
    "        tree.children[1].dist = 0.\n",
    "        last_success.dist = total-remainder\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_describe(tree):\n",
    "    n_leaves = len(tree.get_leaves())\n",
    "    n_nodes = len([i for i in tree.traverse()])\n",
    "    total_bl = np.sum([i.dist for i in tree.traverse()])\n",
    "    return n_leaves, n_nodes, total_bl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensuring the same results as the (slower) built in ete3 mid-point method\n",
    "\n",
    "**Also worth noting that the ete3 mid-point method doesn't root at the actual mid-point of the tree but rather the mid-point of the mid-point branch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-4d2c7778bd5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#     print(tree_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mete3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_midpoint_outgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_outgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ma_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ete3/coretype/tree.py\u001b[0m in \u001b[0;36mget_midpoint_outgroup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tree_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0mnA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2A_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_farthest_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m         \u001b[0mnB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2B_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_farthest_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0moutgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ete3/coretype/tree.py\u001b[0m in \u001b[0;36mget_farthest_node\u001b[0;34m(self, topology_only)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mch\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                         \u001b[0mfnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_farthest_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopology_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopology_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                         \u001b[0mfnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ete3/coretype/tree.py\u001b[0m in \u001b[0;36mget_farthest_leaf\u001b[0;34m(self, topology_only, is_leaf_fn)\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \"\"\"\n\u001b[1;32m   1107\u001b[0m         min_node, min_dist, max_node, max_dist = self._get_farthest_and_closest_leaves(\n\u001b[0;32m-> 1108\u001b[0;31m         topology_only=topology_only, is_leaf_fn=is_leaf_fn)\n\u001b[0m\u001b[1;32m   1109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ete3/coretype/tree.py\u001b[0m in \u001b[0;36m_get_farthest_and_closest_leaves\u001b[0;34m(self, topology_only, is_leaf_fn)\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mmax_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_prepostorder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_leaf_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_leaf_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/ete3/coretype/tree.py\u001b[0m in \u001b[0;36miter_prepostorder\u001b[0;34m(self, is_leaf_fn)\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0m_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mto_visit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_visit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "# for tree_file in glob.glob('../Data/OMA_orthologs/5204_4890/*.treefile')[:]:\n",
    "# for tree_file in glob.glob('../Data/OMA_orthologs/5204_4890_33511_33317/*.treefile')[:]:\n",
    "for tree_file in glob.glob('../Data/OMA_orthologs/5204_4890_33511_33317_33090/*.treefile')[:]:\n",
    "#     print(tree_file)\n",
    "    tree = ete3.Tree(tree_file, format=0)\n",
    "    R = tree.get_midpoint_outgroup()\n",
    "    tree.set_outgroup(R)\n",
    "    a_orig = set([i.name for i in tree.children[0].get_leaves()])\n",
    "    b_orig = set([i.name for i in tree.children[1].get_leaves()])\n",
    "    orig_desc = full_describe(tree)\n",
    "    \n",
    "    tree = ete3.Tree(tree_file, format=0)\n",
    "    MP_root_ete3(tree)\n",
    "    a_new = set([i.name for i in tree.children[0].get_leaves()])\n",
    "    b_new = set([i.name for i in tree.children[1].get_leaves()])\n",
    "    new_desc = full_describe(tree)\n",
    "    \n",
    "    assert orig_desc[:-1] == new_desc[:-1]\n",
    "    assert np.isclose(orig_desc[-1], new_desc[-1])\n",
    "    assert (a_orig==a_new and b_orig==b_new) or (a_orig==b_new and b_orig==a_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinVar development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../Tree_weighting/Code')\n",
    "import weighting_methods_ete3\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from statsmodels.stats.weightstats import DescrStatsW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinVar_root_ete3(my_tree, weights_type='None'):\n",
    "    \"\"\" \n",
    "\n",
    "    \"\"\"\n",
    "    initial_depths = [my_tree.get_distance(i) for i in my_tree.get_leaves()]\n",
    "    depths_array_dict = {}\n",
    "    depths_array_dict[my_tree] = np.array(initial_depths)\n",
    "    weights_array_dict = {}\n",
    "    if weights_type == 'None':\n",
    "        weights_array_dict[my_tree] = np.array([1.0 for i in my_tree.get_leaves()])\n",
    "        weights_update_fxn = no_weights_update\n",
    "        branchscan_fxn = MinVar_branchscan\n",
    "    \n",
    "    elif weights_type == 'GSC':\n",
    "        weighting_methods_ete3.GSC_ete3(my_tree)\n",
    "        weights_array_dict[my_tree] = np.array([i.weight for i in my_tree.get_leaves()])\n",
    "        weights_update_fxn = update_GSC_array_dict\n",
    "        branchscan_fxn = MinVar_branchscan_GSC\n",
    "    else:\n",
    "        print('Need to give me a valid weights_type (currently None or GSC)')\n",
    "    finished_count = compile_array_dicts(my_tree, weights_array_dict, depths_array_dict, weights_update_fxn)\n",
    "    results_dict = MinVar_optimize_all(my_tree, weights_array_dict, depths_array_dict, branchscan_fxn)\n",
    "    return results_dict, depths_array_dict, weights_array_dict\n",
    "\n",
    "def compile_array_dicts(node, weights_array_dict, depths_array_dict, weights_update_fxn, finished_count=0):\n",
    "    if not node.is_root():      \n",
    "        update_depth_array_dict(node, depths_array_dict, finished_count)\n",
    "        weights_update_fxn(node, weights_array_dict, finished_count)\n",
    "    if len(node.children) == 0:\n",
    "        finished_count += 1   \n",
    "    elif len(node.children) == 2:\n",
    "        l_child, r_child = node.children\n",
    "        finished_count = compile_array_dicts(l_child, weights_array_dict, depths_array_dict, weights_update_fxn, finished_count)\n",
    "        finished_count = compile_array_dicts(r_child, weights_array_dict, depths_array_dict, weights_update_fxn, finished_count)\n",
    "    else:\n",
    "        print('Probable f up')\n",
    "    return finished_count\n",
    "\n",
    "def update_depth_array_dict(node, depths_array_dict, finished_count):\n",
    "    ds_count = len(node.get_leaves())\n",
    "    parent = node.up\n",
    "    new_array = np.array(depths_array_dict[parent])\n",
    "    new_array[finished_count:finished_count+ds_count] -= node.dist\n",
    "    #Add the branch length to all the upstream clades (two sets)\n",
    "    new_array[:finished_count] += node.dist\n",
    "    new_array[finished_count+ds_count:] += node.dist\n",
    "    #Update the dictionary\n",
    "    depths_array_dict[node] = new_array\n",
    "    return\n",
    "\n",
    "def no_weights_update(node, weights_array_dict, finished_count):\n",
    "    weights_array_dict[node] = weights_array_dict[node.up]\n",
    "    return\n",
    "\n",
    "def update_GSC_array_dict(node, weights_array_dict, finished_count):\n",
    "    ds_count = len(node.get_leaves())\n",
    "    parent = node.up\n",
    "    new_array = np.array(weights_array_dict[parent])\n",
    "    #This is the total \"weight\" to reclaim from the downstream terms and distribute to the upstreams\n",
    "    bl_to_disperse = node.dist\n",
    "    #Recover from downstream terminals\n",
    "    current_ds_weights = np.sum(new_array[finished_count:finished_count+ds_count])\n",
    "    if current_ds_weights > 0:\n",
    "        to_subtract = new_array[finished_count:finished_count+ds_count]/current_ds_weights*-1*bl_to_disperse\n",
    "    else:\n",
    "        to_subtract = np.zeros_like(new_array[finished_count:finished_count+ds_count])\n",
    "    #Disperse to upstream terminals\n",
    "    current_us_weights = np.sum(new_array[:finished_count]) + np.sum(new_array[finished_count+ds_count:]) \n",
    "    if current_us_weights > 0:\n",
    "        to_add_a = new_array[:finished_count] / current_us_weights * bl_to_disperse  \n",
    "        to_add_b = new_array[finished_count+ds_count:] / current_us_weights * bl_to_disperse\n",
    "    else:\n",
    "        to_add_a = np.zeros_like(new_array[:finished_count])  \n",
    "        to_add_b = np.zeros_like(new_array[finished_count+ds_count:])      \n",
    "    assert  np.isclose(np.sum(to_add_a) + np.sum(to_add_b) + np.sum(to_subtract), 0.)\n",
    "    #et voila\n",
    "    new_array = new_array + np.concatenate((to_add_a, to_subtract, to_add_b))\n",
    "    weights_array_dict[node] = new_array \n",
    "    return\n",
    "\n",
    "def MinVar_optimize_all(my_tree, weights_array_dict, depths_array_dict, branchscan_fxn):\n",
    "    results_dict = {}\n",
    "    for node in weights_array_dict.keys():\n",
    "        if node.is_root():\n",
    "            continue\n",
    "        print(node.name)\n",
    "        leaves = node.get_leaves()\n",
    "        ds_count = len(leaves)\n",
    "        first = leaves[0]\n",
    "        finished_count = my_tree.get_leaves().index(first)\n",
    "        depths_array = depths_array_dict[node]\n",
    "        weights_array = weights_array_dict[node]\n",
    "        ###################################################\n",
    "        #Root-to-tip distances for all downstream terminals\n",
    "        ###################################################\n",
    "        downstream_dists = np.array(depths_array[finished_count:finished_count+ds_count])\n",
    "        #And all upstream terminals\n",
    "        upstream_dists = np.concatenate((depths_array[:finished_count],\\\n",
    "                                         depths_array[finished_count+ds_count:]))\n",
    "        ###################################################\n",
    "        #Weights for all downstream terminals\n",
    "        ###################################################\n",
    "        downstream_weights = np.array(weights_array[finished_count:finished_count+ds_count])\n",
    "        #And all upstream terminals\n",
    "        upstream_weights = np.concatenate((weights_array[:finished_count],\\\n",
    "                                           weights_array[finished_count+ds_count:]))\n",
    "        \n",
    "        ###################################################\n",
    "        #Set the bounds and optimize the GSC specific function\n",
    "        ###################################################\n",
    "        bl_bounds = np.array([[0., node.dist]])\n",
    "        #Valid options for method are L-BFGS-B, SLSQP and TNC\n",
    "        res = minimize(branchscan_fxn, np.array(np.mean(bl_bounds)),\\\n",
    "                              args=(downstream_dists, upstream_dists,\\\n",
    "                                    downstream_weights, upstream_weights),\\\n",
    "                              bounds=bl_bounds, method='L-BFGS-B')\n",
    "        results_dict[node] = res\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def MinVar_branchscan(modifier, ds_dists, us_dists, ds_weights, us_weights):\n",
    "        temp_ds_dists = ds_dists + modifier\n",
    "        temp_us_dists = us_dists - modifier\n",
    "        all_dists = np.concatenate((temp_ds_dists, temp_us_dists))\n",
    "        all_weights = np.concatenate((ds_weights, us_weights))\n",
    "        dsw = DescrStatsW(all_dists, all_weights)\n",
    "        return dsw.var\n",
    "\n",
    "def MinVar_branchscan_GSC(modifier, ds_dists, us_dists, ds_weights, us_weights):\n",
    "        temp_ds_dists = ds_dists + modifier\n",
    "        temp_us_dists = us_dists - modifier\n",
    "        all_dists = np.concatenate((temp_ds_dists, temp_us_dists))\n",
    "\n",
    "        ###########################################################################\n",
    "        #Now adjust the downstream and upstream weights\n",
    "        ###########################################################################\n",
    "        #First get the total downstream weights\n",
    "        total_ds = np.sum(ds_weights)\n",
    "        #Divide up the added branch length (modifier) across the downstream weights\n",
    "        if total_ds != 0:\n",
    "            temp_ds_weights = ds_weights + (ds_weights/total_ds*modifier)\n",
    "        #Special case if nothing is downstream (for terminal branches)\n",
    "        else:\n",
    "            temp_ds_weights = ds_weights + modifier\n",
    "        #Get the total old upstream weights\n",
    "        total_us = np.sum(us_weights)\n",
    "        #Reclaim the branch length (modifier) from all the upstream weights\n",
    "        if total_us != 0:\n",
    "            temp_us_weights = us_weights - (us_weights/total_us*modifier)\n",
    "        #Special case for terminal branches\n",
    "        else:\n",
    "            print('This condition should perhaps never occur and should be investigated')\n",
    "            temp_us_weights = us_weights - modifier\n",
    "        #Put all the weights together\n",
    "        all_weights = np.concatenate((temp_ds_weights, temp_us_weights))\n",
    "        #In GSC weighting, the weights can't be less than the distance! Minor numerical rounding errors can\n",
    "        #cause this to happen\n",
    "        all_weights = np.minimum(all_weights, all_dists) \n",
    "        #Finally putting that boolean I've been passing around to use. Basically this is a re-scaling\n",
    "        #of the GSC weights that I came up with that expresses each GSC weight for a given terminal\n",
    "        #as a fraction of its total possible weight (its depth). In practice, it is a less dramatic \n",
    "        #weighting scheme than the non-normalized counterpart.\n",
    "        ###########################################################################\n",
    "        #Calculate weighted variance and return\n",
    "        ###########################################################################\n",
    "        dsw = DescrStatsW(all_dists, all_weights)\n",
    "        return dsw.var\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "A\n",
      "B\n",
      "C\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "test_tree = ete3.Tree('(((A:20, B:20):30, C:31):30, D:80);')\n",
    "results_dict, depths_array_dict, weights_array_dict = MinVar_root_ete3(test_tree, weights_type='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TreeNode' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-672e6304233f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TreeNode' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "for i in test_tree.get_leaves():\n",
    "    print(i.name, i.dist, i.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[301.0, 241.0, 241.0, 281.0, 281.0, 303.0, 461.0]\n"
     ]
    }
   ],
   "source": [
    "print([np.sum(i) for i in depths_array_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "print([np.sum(i) for i in weights_array_dict.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([array([80., 80., 61., 80.]), array([ 50.,  50.,  31., 110.]), array([ 20.,  20.,  61., 140.]), array([  0.,  40.,  81., 160.]), array([ 40.,   0.,  81., 160.]), array([ 81.,  81.,   0., 141.]), array([160., 160., 141.,   0.])])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depths_array_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([array([1., 1., 1., 1.]), array([1., 1., 1., 1.]), array([1., 1., 1., 1.]), array([1., 1., 1., 1.]), array([1., 1., 1., 1.]), array([1., 1., 1., 1.]), array([1., 1., 1., 1.])])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_array_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      /-A\n",
      "   /-|\n",
      "--|   \\-B\n",
      "  |\n",
      "   \\-C       fun: 67.6875\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-4.74999808])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 4\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([30.])\n",
      "\n",
      "   /-A\n",
      "--|\n",
      "   \\-B       fun: 885.1875\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-20.50002195])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 4\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([30.])\n",
      "\n",
      "--A       fun: 2400.1875\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-40.25005182])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 4\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([20.])\n",
      "\n",
      "--B       fun: 2400.1875\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-40.25005182])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 4\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([20.])\n",
      "\n",
      "--C       fun: 885.1875\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([-29.25002036])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 4\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([31.])\n",
      "\n",
      "--D       fun: 60.1666666666723\n",
      " hess_inv: <1x1 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([3.55271368e-06])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 6\n",
      "      nit: 2\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([76.83333607])\n"
     ]
    }
   ],
   "source": [
    "for i,j in results_dict.items():\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
